# âš™ï¸ Backend â€“ Medical Care AI Assistant (FastAPI)

This is the backend for the **Medical Care AI Assistant**, built with FastAPI. It powers intelligent chat, medical analysis, 
image processing, and research features using Gemini and Tavily APIs. The system supports bilingual interaction (English and French), 
remembers user-specific facts, and is designed for clarity, scalability, and modularity.

**Live deployment:** [https://medicare-ai-backend-bnrt.onrender.com](https://medicare-ai-backend-bnrt.onrender.com)

---

## ğŸ› ï¸ Tech Stack

- **FastAPI** â€“ Web framework for building APIs  
- **Uvicorn** â€“ ASGI server for deployment  
- **Pydantic** â€“ Data validation and serialization  
- **httpx / requests** â€“ External API calls  
- **dotenv** â€“ Environment variable management  

---

## ğŸ“ Folder Structure

```
Medical Care AI/
â”œâ”€â”€ .vscode/                    # Editor settings
â”œâ”€â”€ render.yaml                 # Deployment config
â”œâ”€â”€ README.md                   # Project documentation
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ .env                    # Environment variables
â”‚   â”œâ”€â”€ .env.example            # Sample env file
â”‚   â”œâ”€â”€ .gitignore              # Git exclusions
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ venv/                   # Virtual environment
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py           # Global config
â”‚       â”œâ”€â”€ main.py             # App entry point
â”‚       â”œâ”€â”€ chains/
â”‚       â”‚   â”œâ”€â”€ analysis_chain.py   # Handles medical analysis logic
â”‚       â”‚   â””â”€â”€ chat_chain.py       # Handles chat flow logic with memory injection
â”‚       â”œâ”€â”€ middleware/
â”‚       â”‚   â””â”€â”€ usage_tracker.py    # Tracks usage and limits
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â””â”€â”€ schemas.py          # Pydantic models for requests/responses
â”‚       â”œâ”€â”€ routes/
â”‚       â”‚   â”œâ”€â”€ analysis.py         # Endpoint for medical analysis
â”‚       â”‚   â”œâ”€â”€ chat.py             # Bilingual chat endpoint with memory
â”‚       â”‚   â”œâ”€â”€ health.py           # Health check endpoint
â”‚       â”‚   â”œâ”€â”€ image.py            # Image processing endpoint
â”‚       â”‚   â””â”€â”€ research.py         # Web research endpoint
â”‚       â””â”€â”€ services/
â”‚           â”œâ”€â”€ gemini_service.py   # Gemini API integration
â”‚           â””â”€â”€ tavily_service.py   # Tavily API integration
```

---

## ğŸš€ How It Works

Each module is responsible for a specific domain:

| Module         | Purpose                                                  |
|----------------|-----------------------------------------------------------|
| `chains/`      | Defines logic flows for chat and analysis                 |
| `middleware/`  | Tracks usage and enforces rate limits                     |
| `models/`      | Defines request and response schemas                      |
| `routes/`      | Exposes API endpoints for chat, analysis, health, image, and research |
| `services/`    | Handles external API calls to Gemini and Tavily          |
| `main.py`      | Initializes FastAPI app and includes routers              |
| `config.py`    | Loads environment variables and global settings           |

---

## ğŸ’¬ Chat Endpoint

### `/chat` â€“ Intelligent, bilingual assistant

- Accepts `user_id`, `message`, and `language` (`en` or `fr`)
- Responds in the selected language
- Detects `"remember that"` phrases and stores facts for future use
- Injects memory into chat flow for personalized responses

**Example request:**

```json
{
  "user_id": "empress123",
  "message": "Remember that Iâ€™m allergic to penicillin",
  "language": "en"
}
```

---

## ğŸ” Rate Limiting & Usage Tracking

- Implemented in `usage_tracker.py`
- Tracks requests per IP or session
- Enforces:
  - **Gemini**: 200 requests/day
  - **Tavily**: 1000 requests/month
- Returns `429 Too Many Requests` if limits are exceeded

---

## ğŸ”‘ Environment Variables

Stored in `.env` and loaded via `config.py`:

```
GEMINI_API_KEY=your_google_key
TAVILY_API_KEY=your_tavily_key
GEMINI_DAILY_LIMIT=200
TAVILY_MONTHLY_LIMIT=1000
```

Use `.env.example` as a template for setup.

---

## ğŸ§ª Local Setup

1. Create a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # or venv\Scripts\activate on Windows
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Add your `.env` file with valid API keys.

4. Run the server:
   ```bash
   uvicorn app.main:app --reload
   ```

5. Test endpoints using Postman, curl, or your frontend.

---

## ğŸ’¡ Notes

- Gemini and Tavily quotas reset daily/monthlyâ€”track usage carefully.
- Modular structure makes it easy to expand features or refactor logic.
- You can add authentication, logging, or database support as needed.
- Memory is stored per `user_id` and injected into chat responses.

---

## ğŸ™Œ Credits

Backend crafted by **Empress ğŸ‘‘** and her AI companion.  
Powered by FastAPI, Gemini, Tavily, and a clear vision for intelligent healthcare support.
```