# ⚙️ Backend – Medical Care AI Assistant (FastAPI)

This is the backend for the **Medical Care AI Assistant**, built with FastAPI. It powers intelligent chat, medical analysis, 
image processing, and research features using Gemini and Tavily APIs. The system supports bilingual interaction (English and French), 
remembers user-specific facts, and is designed for clarity, scalability, and modularity.

**Live deployment:** [https://medicare-ai-backend-bnrt.onrender.com](https://medicare-ai-backend-bnrt.onrender.com)

---

## 🛠️ Tech Stack

- **FastAPI** – Web framework for building APIs  
- **Uvicorn** – ASGI server for deployment  
- **Pydantic** – Data validation and serialization  
- **httpx / requests** – External API calls  
- **dotenv** – Environment variable management  

---

## 📁 Folder Structure

```
Medical Care AI/
├── .vscode/                    # Editor settings
├── render.yaml                 # Deployment config
├── README.md                   # Project documentation
├── backend/
│   ├── .env                    # Environment variables
│   ├── .env.example            # Sample env file
│   ├── .gitignore              # Git exclusions
│   ├── requirements.txt        # Python dependencies
│   ├── venv/                   # Virtual environment
│   └── app/
│       ├── __init__.py
│       ├── config.py           # Global config
│       ├── main.py             # App entry point
│       ├── chains/
│       │   ├── analysis_chain.py   # Handles medical analysis logic
│       │   └── chat_chain.py       # Handles chat flow logic with memory injection
│       ├── middleware/
│       │   └── usage_tracker.py    # Tracks usage and limits
│       ├── models/
│       │   └── schemas.py          # Pydantic models for requests/responses
│       ├── routes/
│       │   ├── analysis.py         # Endpoint for medical analysis
│       │   ├── chat.py             # Bilingual chat endpoint with memory
│       │   ├── health.py           # Health check endpoint
│       │   ├── image.py            # Image processing endpoint
│       │   └── research.py         # Web research endpoint
│       └── services/
│           ├── gemini_service.py   # Gemini API integration
│           └── tavily_service.py   # Tavily API integration
```

---

## 🚀 How It Works

Each module is responsible for a specific domain:

| Module         | Purpose                                                  |
|----------------|-----------------------------------------------------------|
| `chains/`      | Defines logic flows for chat and analysis                 |
| `middleware/`  | Tracks usage and enforces rate limits                     |
| `models/`      | Defines request and response schemas                      |
| `routes/`      | Exposes API endpoints for chat, analysis, health, image, and research |
| `services/`    | Handles external API calls to Gemini and Tavily          |
| `main.py`      | Initializes FastAPI app and includes routers              |
| `config.py`    | Loads environment variables and global settings           |

---

## 💬 Chat Endpoint

### `/chat` – Intelligent, bilingual assistant

- Accepts `user_id`, `message`, and `language` (`en` or `fr`)
- Responds in the selected language
- Detects `"remember that"` phrases and stores facts for future use
- Injects memory into chat flow for personalized responses

**Example request:**

```json
{
  "user_id": "empress123",
  "message": "Remember that I’m allergic to penicillin",
  "language": "en"
}
```

---

## 🔐 Rate Limiting & Usage Tracking

- Implemented in `usage_tracker.py`
- Tracks requests per IP or session
- Enforces:
  - **Gemini**: 200 requests/day
  - **Tavily**: 1000 requests/month
- Returns `429 Too Many Requests` if limits are exceeded

---

## 🔑 Environment Variables

Stored in `.env` and loaded via `config.py`:

```
GEMINI_API_KEY=your_google_key
TAVILY_API_KEY=your_tavily_key
GEMINI_DAILY_LIMIT=200
TAVILY_MONTHLY_LIMIT=1000
```

Use `.env.example` as a template for setup.

---

## 🧪 Local Setup

1. Create a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # or venv\Scripts\activate on Windows
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Add your `.env` file with valid API keys.

4. Run the server:
   ```bash
   uvicorn app.main:app --reload
   ```

5. Test endpoints using Postman, curl, or your frontend.

---

## 💡 Notes

- Gemini and Tavily quotas reset daily/monthly—track usage carefully.
- Modular structure makes it easy to expand features or refactor logic.
- You can add authentication, logging, or database support as needed.
- Memory is stored per `user_id` and injected into chat responses.

---

## 🙌 Credits

Backend crafted by **Empress 👑** and her AI companion.  
Powered by FastAPI, Gemini, Tavily, and a clear vision for intelligent healthcare support.
```